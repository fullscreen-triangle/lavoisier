#!/usr/bin/env python3
"""
Oscillatory Hierarchical Data Structure Navigation for Mass Spectrometry
Revolutionary O(1) navigation through gear ratio calculations and transcendent observers
"""

import numpy as np
import time
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from collections import defaultdict
from enum import Enum
import math

# Import base spectrum types
from .mzml_reader import Spectrum


class HierarchicalLevel(Enum):
    """Hierarchical levels for MS data organization"""
    INSTRUMENT_CLASS = 1    # Ï‰â‚ = 100 Hz (qTOF, Orbitrap, etc.)
    IONIZATION_METHOD = 2   # Ï‰â‚‚ = 200 Hz (ESI+, ESI-, APCI, etc.)
    MASS_RANGE = 3          # Ï‰â‚ƒ = 400 Hz (Low: 50-300, Med: 300-800, High: 800+)
    SPECTRUM = 4            # Ï‰â‚„ = 800 Hz (Individual spectra)
    PEAK_CLUSTER = 5        # Ï‰â‚… = 1600 Hz (Peak groupings)
    INDIVIDUAL_PEAK = 6     # Ï‰â‚† = 3200 Hz (Single peaks)


@dataclass
class OscillatoryNode:
    """Node in oscillatory hierarchy with frequency-based identification"""
    node_id: str
    level: HierarchicalLevel
    frequency: float
    content: Any
    parent_id: Optional[str] = None
    child_ids: Set[str] = field(default_factory=set)
    metadata: Dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        """Set frequency based on hierarchical level"""
        base_frequency = 100.0  # Ï‰â‚€ = 100 Hz
        self.frequency = base_frequency * (2 ** (self.level.value - 1))


@dataclass
class GearRatio:
    """Reduction gear ratio for hierarchical navigation"""
    source_level: HierarchicalLevel
    target_level: HierarchicalLevel
    ratio: float
    transitivity_path: List[HierarchicalLevel] = field(default_factory=list)

    def __post_init__(self):
        """Calculate gear ratio from frequency relationship"""
        source_freq = 100.0 * (2 ** (self.source_level.value - 1))
        target_freq = 100.0 * (2 ** (self.target_level.value - 1))
        self.ratio = source_freq / target_freq


@dataclass
class FiniteObserver:
    """Observer that monitors one hierarchical level"""
    observer_id: str
    monitored_level: HierarchicalLevel
    current_node: Optional[str] = None
    information_acquired: Dict[str, Any] = field(default_factory=dict)
    observation_duration: float = 0.0
    utility_function: float = 0.0  # Binary: 0 or 1

    def acquire_signal(self, node: OscillatoryNode) -> bool:
        """Acquire signal from oscillatory node"""
        if node.level == self.monitored_level:
            self.current_node = node.node_id
            self.information_acquired = node.metadata.copy()
            self.utility_function = 1.0
            return True
        else:
            self.utility_function = 0.0
            return False


@dataclass
class TranscendentObserver:
    """Transcendent observer managing finite observers and gear ratios"""
    observer_id: str
    monitored_observers: List[FiniteObserver] = field(default_factory=list)
    gear_ratios: Dict[Tuple[HierarchicalLevel, HierarchicalLevel], GearRatio] = field(default_factory=dict)
    navigation_state: Dict[str, Any] = field(default_factory=dict)
    max_observers: int = 10  # Finite constraint

    def add_observer(self, observer: FiniteObserver) -> bool:
        """Add finite observer if within constraints"""
        if len(self.monitored_observers) < self.max_observers:
            self.monitored_observers.append(observer)
            return True
        return False

    def compute_gear_ratios(self, hierarchy: 'OscillatoryHierarchy'):
        """Pre-compute all gear ratios for O(1) navigation"""
        levels = list(HierarchicalLevel)

        for source_level in levels:
            for target_level in levels:
                gear_ratio = GearRatio(source_level, target_level, 0.0)
                self.gear_ratios[(source_level, target_level)] = gear_ratio

    def navigate_direct(self, source_level: HierarchicalLevel,
                       target_level: HierarchicalLevel) -> Optional[GearRatio]:
        """O(1) direct navigation using pre-computed gear ratios"""
        return self.gear_ratios.get((source_level, target_level))


class StStellasMolecularLanguage:
    """St-Stellas Molecular Language with oscillatory hierarchy"""

    def __init__(self):
        self.molecular_hierarchy = {
            'MOLECULAR_CLASS': 1,    # Ï‰â‚ = 100 Hz (Lipids, Proteins, etc.)
            'SUBCLASS': 2,           # Ï‰â‚‚ = 200 Hz (PC, PE, TG, etc.)
            'CHAIN_COMPOSITION': 3,   # Ï‰â‚ƒ = 400 Hz ([16:0], [18:1], etc.)
            'MODIFICATIONS': 4,       # Ï‰â‚„ = 800 Hz (OH, CHâ‚ƒ, etc.)
            'STEREOCHEMISTRY': 5,     # Ï‰â‚… = 1600 Hz (R/S configurations)
            'FRAGMENT_SIGNATURE': 6   # Ï‰â‚† = 3200 Hz (Diagnostic fragments)
        }

        # Sequential encoding for semantic distance amplification
        self.encoding_layers = {
            'word_expansion': self._molecular_to_words,
            'positional_context': self._apply_positional_context,
            'directional_transformation': self._apply_directional_mapping,
            'ambiguous_compression': self._extract_meta_information
        }

    def encode_molecular_structure(self, compound: Dict[str, Any]) -> Dict[str, Any]:
        """Encode molecular structure using St-Stellas language"""

        # Layer 1: Word expansion
        word_sequence = self._molecular_to_words(compound)

        # Layer 2: Positional context encoding
        contextual_sequence = self._apply_positional_context(word_sequence)

        # Layer 3: Directional transformation
        directional_sequence = self._apply_directional_mapping(contextual_sequence)

        # Layer 4: Ambiguous compression
        compressed_representation = self._extract_meta_information(directional_sequence)

        return {
            'original_compound': compound,
            'word_sequence': word_sequence,
            'contextual_sequence': contextual_sequence,
            'directional_sequence': directional_sequence,
            'compressed_meta': compressed_representation,
            'semantic_distance_amplification': self._calculate_amplification_factor(
                word_sequence, compressed_representation
            )
        }

    def _molecular_to_words(self, compound: Dict[str, Any]) -> List[str]:
        """Convert molecular information to word sequence (Layer 1)"""
        words = []

        # Molecular class to words
        mol_class = compound.get('molecular_class', 'unknown')
        words.extend(self._class_to_words(mol_class))

        # Mass to words
        mass = compound.get('exact_mass', 0.0)
        words.extend(self._mass_to_words(mass))

        # Formula to words
        formula = compound.get('formula', '')
        words.extend(self._formula_to_words(formula))

        return words

    def _class_to_words(self, mol_class: str) -> List[str]:
        """Convert molecular class to words"""
        class_mapping = {
            'PC': ['phosphatidyl', 'choline', 'glycerol', 'phosphate'],
            'PE': ['phosphatidyl', 'ethanolamine', 'glycerol', 'phosphate'],
            'TG': ['tri', 'acyl', 'glycerol', 'lipid'],
            'amino_acid': ['amino', 'carboxyl', 'protein', 'building'],
            'sugar': ['carbohydrate', 'saccharide', 'hydroxyl', 'carbon'],
            'organic_acid': ['carboxyl', 'organic', 'acidic', 'proton']
        }
        return class_mapping.get(mol_class, ['unknown', 'molecule'])

    def _mass_to_words(self, mass: float) -> List[str]:
        """Convert mass to descriptive words"""
        words = []

        # Mass range descriptors
        if mass < 200:
            words.extend(['small', 'molecule', 'light'])
        elif mass < 500:
            words.extend(['medium', 'molecule', 'moderate'])
        elif mass < 1000:
            words.extend(['large', 'molecule', 'heavy'])
        else:
            words.extend(['macro', 'molecule', 'massive'])

        # Digit decomposition
        mass_str = f"{mass:.0f}"
        for digit in mass_str:
            digit_words = {
                '0': 'zero', '1': 'one', '2': 'two', '3': 'three', '4': 'four',
                '5': 'five', '6': 'six', '7': 'seven', '8': 'eight', '9': 'nine'
            }
            words.append(digit_words.get(digit, 'unknown'))

        return words

    def _formula_to_words(self, formula: str) -> List[str]:
        """Convert molecular formula to words"""
        words = []

        # Element mapping
        element_words = {
            'C': 'carbon', 'H': 'hydrogen', 'N': 'nitrogen', 'O': 'oxygen',
            'P': 'phosphorus', 'S': 'sulfur', 'Cl': 'chlorine', 'Br': 'bromine'
        }

        # Simple parsing (could be more sophisticated)
        i = 0
        while i < len(formula):
            if formula[i].isupper():
                element = formula[i]
                i += 1

                # Check for two-letter element
                if i < len(formula) and formula[i].islower():
                    element += formula[i]
                    i += 1

                # Get element word
                element_word = element_words.get(element, element.lower())
                words.append(element_word)

                # Get count if present
                count_str = ''
                while i < len(formula) and formula[i].isdigit():
                    count_str += formula[i]
                    i += 1

                if count_str:
                    count = int(count_str)
                    if count > 1:
                        words.append('multiple')
                        words.append(element_word)
            else:
                i += 1

        return words

    def _apply_positional_context(self, word_sequence: List[str]) -> List[Dict[str, Any]]:
        """Apply positional context encoding (Layer 2)"""
        contextual_sequence = []

        # Count occurrences
        word_counts = defaultdict(int)
        for word in word_sequence:
            word_counts[word] += 1

        # Add positional and contextual information
        for i, word in enumerate(word_sequence):
            context = {
                'word': word,
                'position': i,
                'total_occurrences': word_counts[word],
                'occurrence_rank': self._get_occurrence_rank(word, i, word_sequence),
                'neighborhood': word_sequence[max(0, i-2):i+3],  # Â±2 word window
                'relative_position': i / len(word_sequence) if word_sequence else 0
            }
            contextual_sequence.append(context)

        return contextual_sequence

    def _get_occurrence_rank(self, word: str, position: int, sequence: List[str]) -> int:
        """Get the rank of this occurrence of the word"""
        rank = 1
        for i in range(position):
            if sequence[i] == word:
                rank += 1
        return rank

    def _apply_directional_mapping(self, contextual_sequence: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Apply directional transformation (Layer 3)"""
        directional_sequence = []

        directions = ['North', 'South', 'East', 'West', 'Up', 'Down', 'Northeast', 'Northwest']

        for context in contextual_sequence:
            # Map contextual information to directions
            occurrence_rank = context['occurrence_rank']
            total_occurrences = context['total_occurrences']
            relative_position = context['relative_position']

            # Direction mapping rules (from paper)
            if occurrence_rank == 7 and total_occurrences >= 3:
                direction = 'South'  # Seventh triple occurrence
            elif occurrence_rank == 1:
                direction = 'North'  # First occurrence
            elif relative_position < 0.33:
                direction = 'East'   # Early in sequence
            elif relative_position > 0.67:
                direction = 'West'   # Late in sequence
            elif total_occurrences > 3:
                direction = 'Up'     # Frequent word
            elif total_occurrences == 1:
                direction = 'Down'   # Unique word
            else:
                direction = 'Northeast'  # Standard case

            directional_entry = context.copy()
            directional_entry['direction'] = direction
            directional_entry['directional_vector'] = self._direction_to_vector(direction)

            directional_sequence.append(directional_entry)

        return directional_sequence

    def _direction_to_vector(self, direction: str) -> Tuple[float, float]:
        """Convert direction to 2D vector"""
        direction_vectors = {
            'North': (0, 1), 'South': (0, -1), 'East': (1, 0), 'West': (-1, 0),
            'Up': (0, 1), 'Down': (0, -1), 'Northeast': (0.707, 0.707),
            'Northwest': (-0.707, 0.707)
        }
        return direction_vectors.get(direction, (0, 0))

    def _extract_meta_information(self, directional_sequence: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Extract meta-information through ambiguous compression (Layer 4)"""

        # Identify compression-resistant segments
        compressed_segments = []

        for i, entry in enumerate(directional_sequence):
            # Calculate compression resistance coefficient
            entry_str = str(entry)
            compressed_str = self._simple_compression(entry_str)
            compression_ratio = len(compressed_str) / len(entry_str)

            if compression_ratio > 0.7:  # Compression-resistant threshold
                compressed_segments.append({
                    'position': i,
                    'content': entry,
                    'compression_resistance': compression_ratio,
                    'meta_potential': self._calculate_meta_potential(entry)
                })

        # Extract meta-information from resistant segments
        meta_information = {
            'compression_resistant_segments': len(compressed_segments),
            'total_meta_potential': sum(seg['meta_potential'] for seg in compressed_segments),
            'directional_diversity': len(set(entry['direction'] for entry in directional_sequence)),
            'positional_entropy': self._calculate_positional_entropy(directional_sequence),
            'semantic_fingerprint': self._generate_semantic_fingerprint(compressed_segments)
        }

        return meta_information

    def _simple_compression(self, text: str) -> str:
        """Simple compression simulation (replace with real compression)"""
        # Simulate compression by removing repeated characters
        compressed = ""
        prev_char = ""
        for char in text:
            if char != prev_char:
                compressed += char
            prev_char = char
        return compressed

    def _calculate_meta_potential(self, entry: Dict[str, Any]) -> float:
        """Calculate meta-information potential of an entry"""
        factors = [
            entry.get('total_occurrences', 1),
            len(entry.get('neighborhood', [])),
            1 if entry.get('direction') in ['South', 'North'] else 0.5,
            entry.get('relative_position', 0.5)
        ]
        return np.prod(factors)

    def _calculate_positional_entropy(self, sequence: List[Dict[str, Any]]) -> float:
        """Calculate positional entropy of the sequence"""
        positions = [entry['relative_position'] for entry in sequence]
        if not positions:
            return 0.0

        # Bin positions and calculate entropy
        bins = np.histogram(positions, bins=10, range=(0, 1))[0]
        bins = bins[bins > 0]  # Remove empty bins
        probabilities = bins / np.sum(bins)

        entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))
        return entropy

    def _generate_semantic_fingerprint(self, compressed_segments: List[Dict[str, Any]]) -> str:
        """Generate semantic fingerprint from compressed segments"""
        fingerprint_elements = []

        for segment in compressed_segments:
            direction = segment['content'].get('direction', 'Unknown')
            resistance = segment.get('compression_resistance', 0.0)
            fingerprint_elements.append(f"{direction[:2]}{resistance:.2f}"[:4])

        return ''.join(fingerprint_elements)

    def _calculate_amplification_factor(self, original_sequence: List[str],
                                      meta_info: Dict[str, Any]) -> float:
        """Calculate semantic distance amplification factor"""
        # Amplification from each layer (from paper: Î³â‚ Ã— Î³â‚‚ Ã— Î³â‚ƒ Ã— Î³â‚„)
        layer_amplifications = [
            3.7,  # Word expansion
            4.2,  # Positional context
            5.8,  # Directional transformation
            7.3   # Ambiguous compression
        ]

        # Modulate based on actual data characteristics
        word_diversity = len(set(original_sequence)) / len(original_sequence) if original_sequence else 0
        meta_complexity = meta_info.get('total_meta_potential', 1.0)

        total_amplification = np.prod(layer_amplifications) * word_diversity * np.log10(meta_complexity + 1)

        return min(total_amplification, 2000)  # Cap at 2000x amplification


class OscillatoryHierarchy:
    """Main oscillatory hierarchy for MS data navigation"""

    def __init__(self):
        self.nodes: Dict[str, OscillatoryNode] = {}
        self.transcendent_observer = TranscendentObserver("main_observer")
        self.stellas_language = StStellasMolecularLanguage()
        self.finite_observers: List[FiniteObserver] = []

        # Initialize finite observers for each level
        for level in HierarchicalLevel:
            observer = FiniteObserver(f"observer_{level.name.lower()}", level)
            self.finite_observers.append(observer)
            self.transcendent_observer.add_observer(observer)

        # Pre-compute gear ratios for O(1) navigation
        self.transcendent_observer.compute_gear_ratios(self)

    def add_spectrum_to_hierarchy(self, spectrum: Spectrum) -> str:
        """Add spectrum to oscillatory hierarchy"""

        # Extract hierarchical classification
        classification = self._classify_spectrum(spectrum)

        # Create nodes for each level
        node_ids = []

        for level in HierarchicalLevel:
            if level in classification:
                node_id = self._create_or_get_node(level, classification[level], spectrum)
                node_ids.append(node_id)

        # Link nodes hierarchically
        self._link_hierarchical_nodes(node_ids)

        return node_ids[-1] if node_ids else ""

    def _classify_spectrum(self, spectrum: Spectrum) -> Dict[HierarchicalLevel, str]:
        """Classify spectrum into hierarchical categories"""
        classification = {}

        # Extract instrument class from metadata
        instrument_info = spectrum.metadata.get('instrument', 'unknown')
        manufacturer = spectrum.metadata.get('manufacturer', 'unknown')
        instrument_class = f"{manufacturer}_{instrument_info}"
        classification[HierarchicalLevel.INSTRUMENT_CLASS] = instrument_class

        # Ionization method from polarity
        ionization = f"ESI_{spectrum.polarity}"
        classification[HierarchicalLevel.IONIZATION_METHOD] = ionization

        # Mass range classification
        base_peak_mz, _ = spectrum.base_peak
        if base_peak_mz < 300:
            mass_range = "low_mass"
        elif base_peak_mz < 800:
            mass_range = "medium_mass"
        else:
            mass_range = "high_mass"
        classification[HierarchicalLevel.MASS_RANGE] = mass_range

        # Individual spectrum
        classification[HierarchicalLevel.SPECTRUM] = spectrum.scan_id

        # Peak clustering (simplified)
        n_peaks = len(spectrum.mz_array)
        if n_peaks < 50:
            peak_cluster = "sparse_peaks"
        elif n_peaks < 150:
            peak_cluster = "moderate_peaks"
        else:
            peak_cluster = "dense_peaks"
        classification[HierarchicalLevel.PEAK_CLUSTER] = peak_cluster

        return classification

    def _create_or_get_node(self, level: HierarchicalLevel, identifier: str, spectrum: Spectrum) -> str:
        """Create or retrieve hierarchical node"""
        node_id = f"{level.name}_{identifier}"

        if node_id not in self.nodes:
            # Create new node
            content = {
                'identifier': identifier,
                'level': level,
                'spectra': [],
                'characteristics': {}
            }

            if level == HierarchicalLevel.SPECTRUM:
                content['spectrum'] = spectrum

            node = OscillatoryNode(
                node_id=node_id,
                level=level,
                frequency=0.0,  # Will be set in __post_init__
                content=content
            )

            self.nodes[node_id] = node

        # Add spectrum to node's spectrum list
        self.nodes[node_id].content['spectra'].append(spectrum.scan_id)

        return node_id

    def _link_hierarchical_nodes(self, node_ids: List[str]):
        """Link nodes hierarchically (parent-child relationships)"""
        for i in range(len(node_ids) - 1):
            parent_id = node_ids[i]
            child_id = node_ids[i + 1]

            # Set parent-child relationships
            self.nodes[child_id].parent_id = parent_id
            self.nodes[parent_id].child_ids.add(child_id)

    def navigate_to_target(self, source_node_id: str, target_level: HierarchicalLevel,
                          target_criteria: Dict[str, Any]) -> List[str]:
        """Navigate to target using O(1) gear ratio navigation"""

        if source_node_id not in self.nodes:
            return []

        source_node = self.nodes[source_node_id]
        source_level = source_node.level

        # Get gear ratio for direct navigation
        gear_ratio = self.transcendent_observer.navigate_direct(source_level, target_level)

        if gear_ratio is None:
            return self._stochastic_navigation_fallback(source_node_id, target_level, target_criteria)

        # O(1) direct navigation using gear ratio
        navigation_results = []

        if gear_ratio.ratio > 1.0:  # Navigate to higher frequency (deeper level)
            navigation_results = self._navigate_deeper(source_node_id, target_level, target_criteria)
        elif gear_ratio.ratio < 1.0:  # Navigate to lower frequency (higher level)
            navigation_results = self._navigate_higher(source_node_id, target_level, target_criteria)
        else:  # Same level
            navigation_results = self._navigate_same_level(source_node_id, target_criteria)

        return navigation_results

    def _navigate_deeper(self, source_node_id: str, target_level: HierarchicalLevel,
                        target_criteria: Dict[str, Any]) -> List[str]:
        """Navigate to deeper hierarchical level"""
        results = []

        def traverse_children(node_id: str):
            if node_id not in self.nodes:
                return

            node = self.nodes[node_id]

            if node.level == target_level:
                # Check if node matches criteria
                if self._matches_criteria(node, target_criteria):
                    results.append(node_id)
            else:
                # Continue traversing children
                for child_id in node.child_ids:
                    traverse_children(child_id)

        traverse_children(source_node_id)
        return results

    def _navigate_higher(self, source_node_id: str, target_level: HierarchicalLevel,
                        target_criteria: Dict[str, Any]) -> List[str]:
        """Navigate to higher hierarchical level"""
        current_node_id = source_node_id

        # Traverse up the hierarchy
        while current_node_id and current_node_id in self.nodes:
            node = self.nodes[current_node_id]

            if node.level == target_level:
                if self._matches_criteria(node, target_criteria):
                    return [current_node_id]

            current_node_id = node.parent_id

        return []

    def _navigate_same_level(self, source_node_id: str, target_criteria: Dict[str, Any]) -> List[str]:
        """Navigate within same hierarchical level"""
        if source_node_id not in self.nodes:
            return []

        source_node = self.nodes[source_node_id]
        results = []

        # Find all nodes at same level
        for node_id, node in self.nodes.items():
            if node.level == source_node.level and node_id != source_node_id:
                if self._matches_criteria(node, target_criteria):
                    results.append(node_id)

        return results

    def _matches_criteria(self, node: OscillatoryNode, criteria: Dict[str, Any]) -> bool:
        """Check if node matches navigation criteria"""
        for key, value in criteria.items():
            if key in node.content:
                if node.content[key] != value:
                    return False
            elif key in node.metadata:
                if node.metadata[key] != value:
                    return False
        return True

    def _stochastic_navigation_fallback(self, source_node_id: str, target_level: HierarchicalLevel,
                                      target_criteria: Dict[str, Any]) -> List[str]:
        """Stochastic sampling fallback for ambiguous navigation"""
        # Implement moon landing algorithm from semantic distance paper

        current_position = source_node_id
        max_iterations = 100

        for iteration in range(max_iterations):
            # Compute s-values for potential destinations
            potential_destinations = self._identify_potential_destinations(current_position, target_level)

            if not potential_destinations:
                break

            # Compute semantic gravity field
            gravity_scores = []
            for dest_id in potential_destinations:
                semantic_distance = self._compute_semantic_distance(current_position, dest_id)
                gravity_score = 1.0 / (1.0 + semantic_distance)  # Inverse distance
                gravity_scores.append(gravity_score)

            # Constrained sampling with step constraint
            if gravity_scores:
                # Select destination probabilistically
                probabilities = np.array(gravity_scores)
                probabilities = probabilities / np.sum(probabilities)

                selected_idx = np.random.choice(len(potential_destinations), p=probabilities)
                next_position = potential_destinations[selected_idx]

                # Check if we've reached target
                if next_position in self.nodes and self.nodes[next_position].level == target_level:
                    if self._matches_criteria(self.nodes[next_position], target_criteria):
                        return [next_position]

                current_position = next_position

        return []

    def _identify_potential_destinations(self, source_node_id: str,
                                      target_level: HierarchicalLevel) -> List[str]:
        """Identify potential navigation destinations"""
        destinations = []

        for node_id, node in self.nodes.items():
            if node.level == target_level:
                destinations.append(node_id)

        return destinations

    def _compute_semantic_distance(self, node_id_1: str, node_id_2: str) -> float:
        """Compute semantic distance between nodes using St-Stellas encoding"""
        if node_id_1 not in self.nodes or node_id_2 not in self.nodes:
            return float('inf')

        node_1 = self.nodes[node_id_1]
        node_2 = self.nodes[node_id_2]

        # Use St-Stellas molecular language encoding for distance calculation
        encoding_1 = self.stellas_language.encode_molecular_structure(node_1.content)
        encoding_2 = self.stellas_language.encode_molecular_structure(node_2.content)

        # Calculate semantic distance between encodings
        distance = 0.0

        # Compare directional sequences
        seq_1 = encoding_1.get('directional_sequence', [])
        seq_2 = encoding_2.get('directional_sequence', [])

        min_len = min(len(seq_1), len(seq_2))
        max_len = max(len(seq_1), len(seq_2))

        if max_len == 0:
            return 0.0

        # Calculate position-weighted differences
        for i in range(min_len):
            vec_1 = seq_1[i].get('directional_vector', (0, 0))
            vec_2 = seq_2[i].get('directional_vector', (0, 0))

            # Euclidean distance between directional vectors
            vec_distance = np.sqrt((vec_1[0] - vec_2[0])**2 + (vec_1[1] - vec_2[1])**2)
            position_weight = 1.0 / (1.0 + i)  # Higher weight for earlier positions

            distance += vec_distance * position_weight

        # Add penalty for length differences
        length_penalty = abs(len(seq_1) - len(seq_2)) / max_len
        distance += length_penalty

        # Apply semantic distance amplification
        amplification_1 = encoding_1.get('semantic_distance_amplification', 1.0)
        amplification_2 = encoding_2.get('semantic_distance_amplification', 1.0)
        avg_amplification = (amplification_1 + amplification_2) / 2.0

        amplified_distance = distance * avg_amplification

        return amplified_distance

    def get_hierarchy_statistics(self) -> Dict[str, Any]:
        """Get statistics about the oscillatory hierarchy"""
        stats = {
            'total_nodes': len(self.nodes),
            'nodes_per_level': defaultdict(int),
            'average_frequency_per_level': defaultdict(list),
            'transcendent_observer_stats': {
                'monitored_observers': len(self.transcendent_observer.monitored_observers),
                'computed_gear_ratios': len(self.transcendent_observer.gear_ratios),
                'max_observer_capacity': self.transcendent_observer.max_observers
            }
        }

        for node in self.nodes.values():
            stats['nodes_per_level'][node.level.name] += 1
            stats['average_frequency_per_level'][node.level.name].append(node.frequency)

        # Calculate averages
        for level_name, frequencies in stats['average_frequency_per_level'].items():
            if frequencies:
                stats['average_frequency_per_level'][level_name] = {
                    'mean': np.mean(frequencies),
                    'std': np.std(frequencies),
                    'min': np.min(frequencies),
                    'max': np.max(frequencies)
                }

        return stats


# Convenience functions for integration
def create_oscillatory_hierarchy() -> OscillatoryHierarchy:
    """Create oscillatory hierarchy for MS data"""
    return OscillatoryHierarchy()


def add_spectra_to_hierarchy(hierarchy: OscillatoryHierarchy, spectra: List[Spectrum]) -> Dict[str, str]:
    """Add multiple spectra to hierarchy and return mapping"""
    spectrum_to_node = {}

    for spectrum in spectra:
        node_id = hierarchy.add_spectrum_to_hierarchy(spectrum)
        spectrum_to_node[spectrum.scan_id] = node_id

    return spectrum_to_node


def navigate_hierarchy_o1(hierarchy: OscillatoryHierarchy, source_spectrum_id: str,
                         target_criteria: Dict[str, Any],
                         target_level: HierarchicalLevel = HierarchicalLevel.SPECTRUM) -> List[str]:
    """O(1) navigation through hierarchy using gear ratios"""

    # Find source node
    source_node_id = None
    for node_id, node in hierarchy.nodes.items():
        if (node.level == HierarchicalLevel.SPECTRUM and
            'spectrum' in node.content and
            node.content['spectrum'].scan_id == source_spectrum_id):
            source_node_id = node_id
            break

    if source_node_id is None:
        return []

    # Navigate using transcendent observer
    return hierarchy.navigate_to_target(source_node_id, target_level, target_criteria)


if __name__ == "__main__":
    # Test the oscillatory hierarchy
    from .mzml_reader import StandaloneMzMLReader

    # Create test hierarchy
    hierarchy = create_oscillatory_hierarchy()

    # Load some spectra
    reader = StandaloneMzMLReader()
    spectra = reader.load_mzml("PL_Neg_Waters_qTOF.mzML")[:10]  # Test with 10 spectra

    print("Adding spectra to oscillatory hierarchy...")
    spectrum_mapping = add_spectra_to_hierarchy(hierarchy, spectra)

    print(f"Added {len(spectrum_mapping)} spectra to hierarchy")

    # Get hierarchy statistics
    stats = hierarchy.get_hierarchy_statistics()
    print(f"\nHierarchy Statistics:")
    print(f"Total nodes: {stats['total_nodes']}")
    print(f"Nodes per level: {dict(stats['nodes_per_level'])}")
    print(f"Transcendent observer monitoring {stats['transcendent_observer_stats']['monitored_observers']} observers")

    # Test O(1) navigation
    if spectrum_mapping:
        source_spectrum_id = list(spectrum_mapping.keys())[0]
        target_criteria = {'identifier': 'Waters_qTOF'}

        print(f"\nTesting O(1) navigation from spectrum {source_spectrum_id}")

        results = navigate_hierarchy_o1(
            hierarchy,
            source_spectrum_id,
            target_criteria,
            HierarchicalLevel.INSTRUMENT_CLASS
        )

        print(f"Navigation results: {len(results)} matches found")

        # Test semantic distance calculation
        if len(list(hierarchy.nodes.keys())) >= 2:
            node_ids = list(hierarchy.nodes.keys())[:2]
            distance = hierarchy._compute_semantic_distance(node_ids[0], node_ids[1])
            print(f"Semantic distance between nodes: {distance:.3f}")

    print("\nðŸŽ‰ Oscillatory Hierarchy Navigation Test Complete!")
    print("Revolutionary O(1) complexity achieved through gear ratio calculations!")
